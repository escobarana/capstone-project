name: Upload Airflow DAGs to S3
on:
  push:
    branches:
      - '*'
  pull_request:
    branches: [ main ]

jobs:
  upload_dags:
    name: Upload Airflow DAGs to S3
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: .
    steps:
      - name: Git checkout
        uses: actions/checkout@v3

      - name: Upload DAG file to S3 bucket
        uses: a-sync/s3-uploader@master
        with:
          args: --acl public-read
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: ${{ secrets.AWS_REGION_NAME }}
          S3_BUCKET: dataminded-academy-capstone-resources
          S3_KEY: dags/airflow_ana.py
          FILE: dags/batch_job.py