name: Upload Airflow DAGs to S3
on:
  push:
    branches:
      - '*'
  pull_request:
    branches: [ main ]

jobs:
  upload_dags:
    name: Upload Airflow DAGs to S3
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: .
    steps:
      - name: Git checkout
        uses: actions/checkout@v3

      - name: Upload DAG to S3 Bucket
        uses: swimlane/s3-upload-file-action@master
        with:
          aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY}}
          aws_bucket: ${{ secrets.S3_BUCKET_NAME }}
          file_path: 'dags/batch_job.py'
          file_mime_type: 'application/x-python-code'
          dest_dir: 'dags'
